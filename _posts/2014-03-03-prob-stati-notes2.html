---
layout: post
title: 概率统计学相关笔记（二）
---

<h2>{{ page.title }}</h2>
<p>
<strong>随机变量的数字特征</strong>：对于一个随机变量，知道了它的CDF或PDF就意味着已经知道了关于这个随机变量的一切。但一般来说，不需要了解一个随机变量的分布(或有时候很难求出随机变量的分布函数)，而只需要它的某些特征，这些特征是和随机变量相关的，某种意义上具有一定的能表征该随机变量的能力，如期望，方差等，这些被称为随机变量的数字特征。它们都是随机变量的CDF的泛函。<strong>注意数字特征并不是随机变量！它们都是一个定值！</strong>只要给出随机变量，那么它的数字特征都是确定的！

<strong>期望(Expectation)</strong>：期望就是通常意义下的平均值，随机变量X的期望\(E(X)=\int x\,\mathrm{d}F(x)\)，通常也把它记作\(\mu_X\)，不混淆的情况下也可省略下标。若\(Y=r(X)\)，那么\(E(Y)=E(r(X))=\int r(x)\,\mathrm{d}F_X(x)\)。上述公式说明要求Y的期望，不必先求出Y的CDF。多个变量的函数处理和单变量一样，若\(Z=r(X,Y)\)，那么\[E(Z)=E((r(X,Y))=\int\int r(x,y)\,\mathrm{d}F(x,y).\]

期望具有相加性，即如果\(X_1,\dots ,X_n\)为随机变量，\(a_1,\dots ,a_n\)为常数，那么\[E\left(\sum_i a_iX_i\ight)=\sum_i a_iE(X_i).\]这个性质不要求这些随机变量之间的独立性，下面的乘法性质要求独立性：若\(X_1,\dots ,X_n\)<strong>为独立随机变量</strong>，则\[E\left(\prod_{i=1}^nX_i\ight)=\prod_iE(X_i).\]

<strong>方差(Variance)</strong>：随机变量X的方差为\(V(X)=E\left((X-\mu)^2\ight)=\int (x-\mu)^2\,\mathrm{d}F(X)\)。方差也记作\(\sigma^2\)。方差的正2次根记作<strong>标准差</strong>，\(sd(X)=\sqrt{V(X)}\)，也记为\(\sigma\)或\(\sigma_X\)。从定义可以看出，方差代表的是随机变量的散布程度。方差也有如下性质：

1.\(V(X)=E(X^2)-\mu^2\)。

2.\(V(aX+b)=a^2V(X)\)，其中a，b都是常数。

3.若\(X_1,\dots ,X_n\)<strong>为独立随机变量</strong>，\(a_1,\dots ,a_n\)为常数，则\[V\left(\sum_{i=1}^na_iX_i\ight)=\sum_{i=1}^na_i^2V(X_i).\]

<strong>E.g.</strong> 设\(X_1,\dots ,X_n\)为随机变量，<strong>样本均值(sample mean)</strong>定义为\[\bar{X_n}=\frac{1}{n}\sum_{i=1}^nX_i,\]<strong>样本方差(sample variance)</strong>定义为\[S_n^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar{X_n})^2.\]<strong>需要注意，\(\bar{X_n}\)与\(S_n^2\)都是随机变量！它们都是多个随机变量的函数！</strong>理解这一点对后面的统计推断相当重要。对于这两个随机变量，可以求出它们的期望和方差。至于求法，可以先求出它们的分布(求它们分布的方法参见<a title="概率统计学相关笔记（一）" href="http://www.narutoacm.com/archives/prob_stati_notes1/" target="_blank">笔记一</a>中随机变量的变换一节)，然后根据定义来求。当然也可以利用期望方差的性质来求。若这些随机变量是独立同分布的，那么有\[E(\bar{X_n})=\mu,V(\bar{X_n})=\frac{\sigma^2}{n},E(S_n^2)=\sigma^2.\]其中\(\mu=E(X_i)\)，\(\sigma^2=V(X_i)\)。

<strong>协方差(covariance)与相关系数(correlation coefficient)</strong>：协方差与相关系数代表的是两个随机变量之间的线性关系的强弱。随机变量X和Y的协方差为\[Cov(X,Y)=E\left((X-\mu_X)(Y-\mu_Y)\ight),\]相关系数为\[\ho=\ho_{X,Y}=\ho(X,Y)=\frac{Cov(X,Y)}{\sigma_X\sigma_Y}.\]可以证明\(Cov(X,Y)=E(XY)-E(X)E(Y)\)，相关系数满足\(-1\leq\ho(X,Y)\leq 1\)，如果\(Y=aX+b\)，其中a，b是常数，那么当a大于0时，相关系数为1，小于0时，为-1。如果X与Y独立，那么协方差和相关系数都为0，但是<strong>反过来不成立</strong>！

对随机变量X，Y(不要求其独立)，\(V(X+Y)=V(X)+V(Y)+2Cov(X,Y)\)，\(V(X-Y)=V(X)+V(Y)-2Cov(X,Y)\)。更一般地，对于随机变量\(X_1,\dots ,X_n\)，有\[V\left( \sum_ia_iX_i \ight)=\sum_ia_i^2V(X_i)+2\sum_{i\lt j}a_ia_jCov(X_i,Y_j).\]

<strong>条件期望(Conditional expectation)</strong>：给定Y=y，X的条件期望为\[E(X|Y=y)=\int xf_{X|Y}(x|y)\,\mathrm{d}x\]注意\(E(X|Y=y)\)它不是一个定值！事实上它是一个关于随机变量Y的函数！当给定Y的一个定值y，\(E(X|Y=y)\)才是一个定值。所以<strong>它实际上是一个随机变量</strong>(随机变量的函数也是随机变量)，记作\(E(X|Y)\)，当Y=y时，它的值为\(E(X|Y=y)\)。

容易证明，对随机变量X，Y，假设其期望均存在，则有\[E\left(E(Y|X)\ight)=E(Y),E\left(E(X|Y)\ight)=E(X).\]更一般地，对任意函数\(r(x,y)\)有\[E\left(E(r(X,Y)|X)\ight)=E(r(X,Y)).\]上述公式被称为<strong>迭代期望法则</strong>。

<strong>条件方差(conditional variance)</strong>：\(V(X|Y=y)=\int (x-\mu(y))^2f(x|y)\,\mathrm{d}x\)，其中，\(\mu(y)=E(X|Y=y)\)。同理\(V(X|Y)\)它也是个随机变量，当Y=y时，它的值为\(V(X|Y=y)\)。可以证明，对于随机变量X和Y，有\[V(X)=E(V(X|Y))+V(E(X|Y)).\]
</p>
<p>{{ page.date | date_to_string }}</p>

